# Multi Retinal Disease Classification Model

![Python](https://img.shields.io/badge/python-3.10+-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-orange.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)

Deep learning models for multi-label retinal disease classification using advanced graph neural networks and vision transformers.

## ğŸ—ï¸ Project Structure

```
Multi-Retinal-Disease-Model/
â”œâ”€â”€ notebooks/              # Kaggle notebooks & experiments
â”‚   â”œâ”€â”€ notebookc18697ca98.ipynb     # Main training notebook
â”‚   â”œâ”€â”€ EDA_Analysis_Clean.ipynb     # Data exploration
â”‚   â”œâ”€â”€ Model_Development.ipynb      # Model development
â”‚   â”œâ”€â”€ 03_Mathematical_Foundations.md
â”‚   â””â”€â”€ 04_Pitch_Deck.md
â”œâ”€â”€ src/                    # Production-ready code
â”‚   â”œâ”€â”€ 02_Model_Development.py      # Model training script
â”‚   â””â”€â”€ mobile_deployment.py         # Mobile deployment utilities
â”œâ”€â”€ models/                 # Trained models & outputs
â”‚   â”œâ”€â”€ checkpoints/        # Model checkpoints
â”‚   â”œâ”€â”€ exports/            # Exported models (ONNX, TorchScript)
â”‚   â””â”€â”€ outputs/            # Training outputs & visualizations
â”œâ”€â”€ deployment/             # Deployment configurations
â”‚   â”œâ”€â”€ setup.sh            # Deployment setup script
â”‚   â””â”€â”€ install_dependencies.sh
â”œâ”€â”€ .github/workflows/      # CI/CD pipelines
â”‚   â””â”€â”€ ml-pipeline.yml     # Automated testing & deployment
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ README.md              # This file
```

## ğŸš€ Quick Start

### 1. Clone the Repository
```bash
git clone https://github.com/mpairwe7/MLOPS_V1.git
cd MLOPS_V1
```

### 2. Setup Environment
```bash
# Run automated setup
./deployment/setup.sh

# Or manually:
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

### 3. Run Training
```bash
# Activate environment
source .venv/bin/activate

# Run training script
python src/02_Model_Development.py

# Or use Jupyter notebooks
jupyter notebook notebooks/
```

## ğŸ§  Models

This project implements 4 state-of-the-art architectures:

| Model | Parameters | Features |
|-------|-----------|----------|
| **GraphCLIP** | ~45M | CLIP + Graph Attention |
| **VisualLanguageGNN** | ~48M | Visual-Language Fusion |
| **SceneGraphTransformer** | ~52M | Spatial Scene Understanding |
| **ViGNN** | ~50M | Visual Graph Neural Network |

### Key Features:
- âœ… Multi-label classification (45 retinal diseases)
- âœ… Cross-validation training (5-fold)
- âœ… Multi-GPU support (parallel training)
- âœ… Memory-optimized for Kaggle (2x T4 GPUs)
- âœ… Mobile deployment ready

## ğŸ“Š Training Configuration

Current setup for **Kaggle 2x T4 GPUs**:

```python
NUM_EPOCHS = 30
BATCH_SIZE = 32
LEARNING_RATE = 0.0001
NUM_CLASSES = 45
K_FOLDS = 5

# GPU Configuration
models_per_gpu = 1  # Memory-safe mode
max_workers = 2     # Parallel training on 2 GPUs
```

## ğŸ“ˆ Performance

| Model | F1 Score | AUC-ROC | Precision | Recall |
|-------|----------|---------|-----------|--------|
| GraphCLIP | TBD | TBD | TBD | TBD |
| VisualLanguageGNN | TBD | TBD | TBD | TBD |
| SceneGraphTransformer | TBD | TBD | TBD | TBD |
| ViGNN | TBD | TBD | TBD | TBD |

## ğŸ”§ Development

### Running Tests
```bash
pytest tests/ -v
```

### Code Formatting
```bash
black src/
flake8 src/
```

### CI/CD Pipeline
- Automated testing on push/PR
- Model validation
- Notebook compatibility checks
- Deployment to production (on main branch)

## ğŸ“ Notebooks

- **notebookc18697ca98.ipynb**: Main training pipeline with all 4 models
- **EDA_Analysis_Clean.ipynb**: Exploratory data analysis
- **Model_Development.ipynb**: Model architecture development
- **Mathematical_Foundations.md**: Mathematical documentation
- **Pitch_Deck.md**: Project presentation

## ğŸš¢ Deployment

### Local Deployment
```bash
./deployment/setup.sh
```

### Kaggle Deployment
```bash
# Upload notebook to Kaggle
# Configure 2x T4 GPU runtime
# Run Cell 46 for parallel training
```

### Production Deployment
```bash
# Export model
python src/mobile_deployment.py --export --model-name GraphCLIP

# Deploy to cloud (configure in .github/workflows/ml-pipeline.yml)
```

## ğŸ“¦ Requirements

- Python 3.10+
- PyTorch 2.0+
- CUDA 11.8+ (for GPU training)
- 32GB RAM (recommended)
- 2x GPU with 16GB VRAM each

See `requirements.txt` for full dependencies.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ‘¥ Authors

- **mpairwe7** - [GitHub Profile](https://github.com/mpairwe7)

## ğŸ™ Acknowledgments

- Kaggle for GPU resources
- PyTorch and timm libraries
- Research papers on graph neural networks and vision transformers

## ğŸ“§ Contact

For questions or collaboration:
- GitHub Issues: [MLOPS_V1/issues](https://github.com/mpairwe7/MLOPS_V1/issues)
- Repository: [MLOPS_V1](https://github.com/mpairwe7/MLOPS_V1)

---

**Note**: This is an active research project. Models are continuously being improved.
