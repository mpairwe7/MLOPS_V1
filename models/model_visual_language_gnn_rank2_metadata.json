{
  "model_info": {
    "name": "VisualLanguageGNN",
    "architecture": "visual_language_gnn",
    "rank": 2,
    "framework": "PyTorch",
    "knowledge_graph_enabled": true
  },
  "architecture": {
    "model_class_name": "VisualLanguageGNN",
    "model_type": "VisualLanguageGNN",
    "architecture_details": {
      "forward_signature": "(x)",
      "layers": {
        "visual_encoder": {
          "type": "MultiResolutionEncoder",
          "is_custom": true,
          "parameters": {
            "training": false,
            "resolutions": [
              224,
              160,
              128
            ]
          }
        },
        "visual_encoder.encoder.patch_embed.proj": {
          "type": "Conv2d",
          "is_custom": false,
          "parameters": {
            "in_channels": 3,
            "out_channels": 384,
            "kernel_size": [
              16,
              16
            ],
            "stride": [
              16,
              16
            ],
            "padding": [
              0,
              0
            ],
            "dilation": [
              1,
              1
            ],
            "groups": 1,
            "bias": true,
            "padding_mode": "zeros"
          }
        },
        "visual_encoder.encoder.blocks.0.attn.qkv": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1152,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.0.attn.proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.0.mlp.fc1": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1536,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.0.mlp.fc2": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 1536,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.1.attn.qkv": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1152,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.1.attn.proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.1.mlp.fc1": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1536,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.1.mlp.fc2": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 1536,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.2.attn.qkv": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1152,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.2.attn.proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.2.mlp.fc1": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1536,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.2.mlp.fc2": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 1536,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.3.attn.qkv": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1152,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.3.attn.proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.3.mlp.fc1": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1536,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.3.mlp.fc2": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 1536,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.4.attn.qkv": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1152,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.4.attn.proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.4.mlp.fc1": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1536,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.4.mlp.fc2": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 1536,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.5.attn.qkv": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1152,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.5.attn.proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.5.mlp.fc1": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1536,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.5.mlp.fc2": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 1536,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.6.attn.qkv": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1152,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.6.attn.proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.6.mlp.fc1": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1536,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.6.mlp.fc2": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 1536,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.7.attn.qkv": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1152,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.7.attn.proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.7.mlp.fc1": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1536,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.7.mlp.fc2": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 1536,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.8.attn.qkv": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1152,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.8.attn.proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.8.mlp.fc1": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1536,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.8.mlp.fc2": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 1536,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.9.attn.qkv": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1152,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.9.attn.proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.9.mlp.fc1": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1536,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.9.mlp.fc2": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 1536,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.10.attn.qkv": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1152,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.10.attn.proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.10.mlp.fc1": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1536,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.10.mlp.fc2": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 1536,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.11.attn.qkv": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1152,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.11.attn.proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.11.mlp.fc1": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1536,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.11.mlp.fc2": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 1536,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.resolution_projections.0.0": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.resolution_projections.1.0": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.resolution_projections.2.0": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.fusion.0": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 1152,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_proj.0": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "region_importance.0": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 192,
            "bias": true
          }
        },
        "region_importance.2": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 192,
            "out_features": 1,
            "bias": true
          }
        },
        "text_proj.0": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 256,
            "out_features": 384,
            "bias": true
          }
        },
        "cross_modal_layers.0": {
          "type": "SparseTopKAttention",
          "is_custom": true,
          "parameters": {
            "training": false,
            "embed_dim": 384,
            "num_heads": 4,
            "head_dim": 96,
            "top_k": 20
          }
        },
        "cross_modal_layers.0.q_proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "cross_modal_layers.0.k_proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "cross_modal_layers.0.v_proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "cross_modal_layers.0.out_proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "cross_modal_layers.1": {
          "type": "SparseTopKAttention",
          "is_custom": true,
          "parameters": {
            "training": false,
            "embed_dim": 384,
            "num_heads": 4,
            "head_dim": 96,
            "top_k": 20
          }
        },
        "cross_modal_layers.1.q_proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "cross_modal_layers.1.k_proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "cross_modal_layers.1.v_proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "cross_modal_layers.1.out_proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "classifier.0": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 768,
            "out_features": 256,
            "bias": true
          }
        },
        "classifier.4": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 256,
            "out_features": 48,
            "bias": true
          }
        }
      },
      "full_structure": "VisualLanguageGNN(\n  (visual_encoder): MultiResolutionEncoder(\n    (encoder): VisionTransformer(\n      (patch_embed): PatchEmbed(\n        (proj): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))\n        (norm): Identity()\n      )\n      (pos_drop): Dropout(p=0.0, inplace=False)\n      (patch_drop): Identity()\n      (norm_pre): Identity()\n      (blocks): Sequential(\n        (0): Block(\n          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (q_norm): Identity()\n            (k_norm): Identity()\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (1): Block(\n          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (q_norm): Identity()\n            (k_norm): Identity()\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (2): Block(\n          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (q_norm): Identity()\n            (k_norm): Identity()\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (3): Block(\n          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (q_norm): Identity()\n            (k_norm): Identity()\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (4): Block(\n          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (q_norm): Identity()\n            (k_norm): Identity()\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (5): Block(\n          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (q_norm): Identity()\n            (k_norm): Identity()\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (6): Block(\n          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (q_norm): Identity()\n            (k_norm): Identity()\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (7): Block(\n          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (q_norm): Identity()\n            (k_norm): Identity()\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (8): Block(\n          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (q_norm): Identity()\n            (k_norm): Identity()\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (9): Block(\n          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (q_norm): Identity()\n            (k_norm): Identity()\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (10): Block(\n          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (q_norm): Identity()\n            (k_norm): Identity()\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (11): Block(\n          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (q_norm): Identity()\n            (k_norm): Identity()\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n      )\n      (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n      (fc_norm): Identity()\n      (head_drop): Dropout(p=0.0, inplace=False)\n      (head): Identity()\n    )\n    (resolution_projections): ModuleList(\n      (0-2): 3 x Sequential(\n        (0): Linear(in_features=384, out_features=384, bias=True)\n        (1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n        (2): GELU(approximate='none')\n      )\n    )\n    (fusion): Sequential(\n      (0): Linear(in_features=1152, out_features=384, bias=True)\n      (1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n      (2): GELU(approximate='none')\n    )\n  )\n  (visual_proj): Sequential(\n    (0): Linear(in_features=384, out_features=384, bias=True)\n    (1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n    (2): GELU(approximate='none')\n  )\n  (region_importance): Sequential(\n    (0): Linear(in_features=384, out_features=192, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=192, out_features=1, bias=True)\n    (3): Sigmoid()\n  )\n  (text_proj): Sequential(\n    (0): Linear(in_features=256, out_features=384, bias=True)\n    (1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n  )\n  (cross_modal_layers): ModuleList(\n    (0-1): 2 x SparseTopKAttention(\n      (q_proj): Linear(in_features=384, out_features=384, bias=True)\n      (k_proj): Linear(in_features=384, out_features=384, bias=True)\n      (v_proj): Linear(in_features=384, out_features=384, bias=True)\n      (out_proj): Linear(in_features=384, out_features=384, bias=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n  )\n  (norms): ModuleList(\n    (0-1): 2 x LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n  )\n  (classifier): Sequential(\n    (0): Linear(in_features=768, out_features=256, bias=True)\n    (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n    (2): GELU(approximate='none')\n    (3): Dropout(p=0.2, inplace=False)\n    (4): Linear(in_features=256, out_features=48, bias=True)\n  )\n)",
      "layer_types_summary": {
        "disease_text_embed": 12288,
        "visual_encoder": 22555008,
        "visual_proj": 148608,
        "region_importance": 74113,
        "text_proj": 99456,
        "cross_modal_layers": 1182720,
        "norms": 1536,
        "classifier": 209712
      },
      "total_parameters": 24283441
    },
    "helper_classes": [],
    "helper_class_definitions": {},
    "includes_knowledge_graph": true,
    "metadata": {
      "includes_helper_classes": false,
      "helper_classes_captured": [],
      "custom_layers_in_architecture": 3,
      "can_be_reconstructed_from_config": true,
      "includes_knowledge_graph": true,
      "requires_dependencies": [
        "torch",
        "torch.nn"
      ]
    }
  },
  "knowledge_graph": {
    "included": true,
    "type": "ClinicalKnowledgeGraph",
    "disease_count": 45,
    "edge_count": 78,
    "features": {
      "disease_relationships": "Captures co-occurrence and clinical patterns",
      "ugandan_epidemiology": "Region-specific disease prevalence data",
      "clinical_reasoning": "Refines predictions using domain knowledge",
      "referral_priority": "Determines urgency for clinical referral"
    }
  },
  "performance": {
    "f1_score": 0.10248889574703673,
    "auc_roc": 0.6494201323460815,
    "inference_time_ms": 2027.788622379303
  },
  "optimization": {
    "techniques": [
      "Structured Pruning",
      "Float16 Quantization"
    ],
    "pruning": {
      "conv_layers": 1,
      "linear_layers": 66,
      "amount": "30-40%"
    },
    "quantization": {
      "type": "Weight-only Float16",
      "method": "Modern (future-proof)",
      "layers": [
        "All"
      ]
    },
    "original_size_mb": 92.63397598266602,
    "optimized_size_mb": 46.31698799133301,
    "compression_ratio": 2.0,
    "inference_speedup": 0.10337914165968148
  },
  "model_specs": {
    "num_classes": 45,
    "disease_names": [
      "DR",
      "ARMD",
      "MH",
      "DN",
      "MYA",
      "BRVO",
      "TSLN",
      "ERM",
      "LS",
      "MS",
      "CSR",
      "ODC",
      "CRVO",
      "TV",
      "AH",
      "ODP",
      "ODE",
      "ST",
      "AION",
      "PT",
      "RT",
      "RS",
      "CRS",
      "EDN",
      "RPEC",
      "MHL",
      "RP",
      "CWS",
      "CB",
      "ODPM",
      "PRH",
      "MNF",
      "HR",
      "CRAO",
      "TD",
      "CME",
      "PTCR",
      "CF",
      "VH",
      "MCA",
      "VS",
      "BRAO",
      "PLQ",
      "HPED",
      "CL"
    ],
    "input_shape": [
      1,
      3,
      224,
      224
    ],
    "output_shape": [
      1,
      45
    ],
    "quantization_dtype": "float16"
  },
  "preprocessing": {
    "mean": [
      0.485,
      0.456,
      0.406
    ],
    "std": [
      0.229,
      0.224,
      0.225
    ],
    "resize": [
      224,
      224
    ]
  },
  "export_info": {
    "export_order": "PyTorch format only for maximum compatibility",
    "formats_skipped": [
      "TFLite",
      "ONNX",
      "TorchScript"
    ],
    "skip_reason": "Focus on PyTorch format for core deployment",
    "knowledge_graph_injected": true
  },
  "deployment": {
    "formats": [
      "PyTorch (.pth)"
    ],
    "server_deployment": "PyTorch (.pth) - Full precision model",
    "api_endpoint": "/predict",
    "max_batch_size": 32,
    "quantization_note": "Uses modern float16 weight-only quantization (replaces deprecated quantize_dynamic)",
    "clinical_features": "Knowledge graph for enhanced clinical reasoning and referral prioritization"
  }
}