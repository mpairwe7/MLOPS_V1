{
  "model_info": {
    "name": "GraphCLIP",
    "architecture": "graphclip",
    "rank": 1,
    "framework": "PyTorch",
    "knowledge_graph_enabled": true
  },
  "architecture": {
    "model_class_name": "GraphCLIP",
    "model_type": "GraphCLIP",
    "architecture_details": {
      "forward_signature": "(x)",
      "layers": {
        "visual_encoder": {
          "type": "MultiResolutionEncoder",
          "is_custom": true,
          "parameters": {
            "training": false,
            "resolutions": [
              224,
              160,
              128
            ]
          }
        },
        "visual_encoder.encoder.patch_embed.proj": {
          "type": "Conv2d",
          "is_custom": false,
          "parameters": {
            "in_channels": 3,
            "out_channels": 384,
            "kernel_size": [
              16,
              16
            ],
            "stride": [
              16,
              16
            ],
            "padding": [
              0,
              0
            ],
            "dilation": [
              1,
              1
            ],
            "groups": 1,
            "bias": true,
            "padding_mode": "zeros"
          }
        },
        "visual_encoder.encoder.blocks.0.attn.qkv": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1152,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.0.attn.proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.0.mlp.fc1": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1536,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.0.mlp.fc2": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 1536,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.1.attn.qkv": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1152,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.1.attn.proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.1.mlp.fc1": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1536,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.1.mlp.fc2": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 1536,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.2.attn.qkv": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1152,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.2.attn.proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.2.mlp.fc1": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1536,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.2.mlp.fc2": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 1536,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.3.attn.qkv": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1152,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.3.attn.proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.3.mlp.fc1": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1536,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.3.mlp.fc2": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 1536,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.4.attn.qkv": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1152,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.4.attn.proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.4.mlp.fc1": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1536,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.4.mlp.fc2": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 1536,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.5.attn.qkv": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1152,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.5.attn.proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.5.mlp.fc1": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1536,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.5.mlp.fc2": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 1536,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.6.attn.qkv": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1152,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.6.attn.proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.6.mlp.fc1": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1536,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.6.mlp.fc2": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 1536,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.7.attn.qkv": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1152,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.7.attn.proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.7.mlp.fc1": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1536,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.7.mlp.fc2": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 1536,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.8.attn.qkv": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1152,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.8.attn.proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.8.mlp.fc1": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1536,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.8.mlp.fc2": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 1536,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.9.attn.qkv": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1152,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.9.attn.proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.9.mlp.fc1": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1536,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.9.mlp.fc2": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 1536,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.10.attn.qkv": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1152,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.10.attn.proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.10.mlp.fc1": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1536,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.10.mlp.fc2": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 1536,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.11.attn.qkv": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1152,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.11.attn.proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.11.mlp.fc1": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 1536,
            "bias": true
          }
        },
        "visual_encoder.encoder.blocks.11.mlp.fc2": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 1536,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.resolution_projections.0.0": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.resolution_projections.1.0": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.resolution_projections.2.0": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_encoder.fusion.0": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 1152,
            "out_features": 384,
            "bias": true
          }
        },
        "visual_proj.0": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "graph_weight_generator.0": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 192,
            "bias": true
          }
        },
        "graph_weight_generator.2": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 192,
            "out_features": 48,
            "bias": true
          }
        },
        "graph_layers.0": {
          "type": "SparseTopKAttention",
          "is_custom": true,
          "parameters": {
            "training": false,
            "embed_dim": 384,
            "num_heads": 4,
            "head_dim": 96,
            "top_k": 16
          }
        },
        "graph_layers.0.q_proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "graph_layers.0.k_proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "graph_layers.0.v_proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "graph_layers.0.out_proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "graph_layers.1": {
          "type": "SparseTopKAttention",
          "is_custom": true,
          "parameters": {
            "training": false,
            "embed_dim": 384,
            "num_heads": 4,
            "head_dim": 96,
            "top_k": 16
          }
        },
        "graph_layers.1.q_proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "graph_layers.1.k_proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "graph_layers.1.v_proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "graph_layers.1.out_proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "cross_attn": {
          "type": "SparseTopKAttention",
          "is_custom": true,
          "parameters": {
            "training": false,
            "embed_dim": 384,
            "num_heads": 4,
            "head_dim": 96,
            "top_k": 24
          }
        },
        "cross_attn.q_proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "cross_attn.k_proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "cross_attn.v_proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "cross_attn.out_proj": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 384,
            "out_features": 384,
            "bias": true
          }
        },
        "classifier.0": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 768,
            "out_features": 256,
            "bias": true
          }
        },
        "classifier.4": {
          "type": "Linear",
          "is_custom": false,
          "parameters": {
            "in_features": 256,
            "out_features": 48,
            "bias": true
          }
        }
      },
      "full_structure": "GraphCLIP(\n  (visual_encoder): MultiResolutionEncoder(\n    (encoder): VisionTransformer(\n      (patch_embed): PatchEmbed(\n        (proj): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))\n        (norm): Identity()\n      )\n      (pos_drop): Dropout(p=0.0, inplace=False)\n      (patch_drop): Identity()\n      (norm_pre): Identity()\n      (blocks): Sequential(\n        (0): Block(\n          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (q_norm): Identity()\n            (k_norm): Identity()\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (1): Block(\n          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (q_norm): Identity()\n            (k_norm): Identity()\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (2): Block(\n          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (q_norm): Identity()\n            (k_norm): Identity()\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (3): Block(\n          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (q_norm): Identity()\n            (k_norm): Identity()\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (4): Block(\n          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (q_norm): Identity()\n            (k_norm): Identity()\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (5): Block(\n          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (q_norm): Identity()\n            (k_norm): Identity()\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (6): Block(\n          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (q_norm): Identity()\n            (k_norm): Identity()\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (7): Block(\n          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (q_norm): Identity()\n            (k_norm): Identity()\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (8): Block(\n          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (q_norm): Identity()\n            (k_norm): Identity()\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (9): Block(\n          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (q_norm): Identity()\n            (k_norm): Identity()\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (10): Block(\n          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (q_norm): Identity()\n            (k_norm): Identity()\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n        (11): Block(\n          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (q_norm): Identity()\n            (k_norm): Identity()\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (ls1): Identity()\n          (drop_path1): Identity()\n          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (ls2): Identity()\n          (drop_path2): Identity()\n        )\n      )\n      (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n      (fc_norm): Identity()\n      (head_drop): Dropout(p=0.0, inplace=False)\n      (head): Identity()\n    )\n    (resolution_projections): ModuleList(\n      (0-2): 3 x Sequential(\n        (0): Linear(in_features=384, out_features=384, bias=True)\n        (1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n        (2): GELU(approximate='none')\n      )\n    )\n    (fusion): Sequential(\n      (0): Linear(in_features=1152, out_features=384, bias=True)\n      (1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n      (2): GELU(approximate='none')\n    )\n  )\n  (visual_proj): Sequential(\n    (0): Linear(in_features=384, out_features=384, bias=True)\n    (1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n    (2): GELU(approximate='none')\n    (3): Dropout(p=0.1, inplace=False)\n  )\n  (graph_weight_generator): Sequential(\n    (0): Linear(in_features=384, out_features=192, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=192, out_features=48, bias=True)\n  )\n  (graph_layers): ModuleList(\n    (0-1): 2 x SparseTopKAttention(\n      (q_proj): Linear(in_features=384, out_features=384, bias=True)\n      (k_proj): Linear(in_features=384, out_features=384, bias=True)\n      (v_proj): Linear(in_features=384, out_features=384, bias=True)\n      (out_proj): Linear(in_features=384, out_features=384, bias=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n  )\n  (graph_norms): ModuleList(\n    (0-1): 2 x LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n  )\n  (cross_attn): SparseTopKAttention(\n    (q_proj): Linear(in_features=384, out_features=384, bias=True)\n    (k_proj): Linear(in_features=384, out_features=384, bias=True)\n    (v_proj): Linear(in_features=384, out_features=384, bias=True)\n    (out_proj): Linear(in_features=384, out_features=384, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (cross_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n  (classifier): Sequential(\n    (0): Linear(in_features=768, out_features=256, bias=True)\n    (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n    (2): GELU(approximate='none')\n    (3): Dropout(p=0.2, inplace=False)\n    (4): Linear(in_features=256, out_features=48, bias=True)\n  )\n)",
      "layer_types_summary": {
        "disease_embeddings": 18432,
        "visual_encoder": 22555008,
        "visual_proj": 148608,
        "graph_weight_generator": 83184,
        "graph_layers": 1182720,
        "graph_norms": 1536,
        "cross_attn": 591360,
        "cross_norm": 768,
        "classifier": 209712
      },
      "total_parameters": 24791328
    },
    "helper_classes": [],
    "helper_class_definitions": {},
    "includes_knowledge_graph": true,
    "metadata": {
      "includes_helper_classes": false,
      "helper_classes_captured": [],
      "custom_layers_in_architecture": 4,
      "can_be_reconstructed_from_config": true,
      "includes_knowledge_graph": true,
      "requires_dependencies": [
        "torch",
        "torch.nn"
      ]
    }
  },
  "knowledge_graph": {
    "included": true,
    "type": "ClinicalKnowledgeGraph",
    "disease_count": 45,
    "edge_count": 78,
    "features": {
      "disease_relationships": "Captures co-occurrence and clinical patterns",
      "ugandan_epidemiology": "Region-specific disease prevalence data",
      "clinical_reasoning": "Refines predictions using domain knowledge",
      "referral_priority": "Determines urgency for clinical referral"
    }
  },
  "performance": {
    "f1_score": 0.10502405903213233,
    "auc_roc": 0.6540065160703534,
    "inference_time_ms": 2068.2845401763916
  },
  "optimization": {
    "techniques": [
      "Structured Pruning",
      "Float16 Quantization"
    ],
    "pruning": {
      "conv_layers": 1,
      "linear_layers": 69,
      "amount": "30-40%"
    },
    "quantization": {
      "type": "Weight-only Float16",
      "method": "Modern (future-proof)",
      "layers": [
        "All"
      ]
    },
    "original_size_mb": 94.5714111328125,
    "optimized_size_mb": 47.28570556640625,
    "compression_ratio": 2.0,
    "inference_speedup": 0.10411261324840358
  },
  "model_specs": {
    "num_classes": 45,
    "disease_names": [
      "DR",
      "ARMD",
      "MH",
      "DN",
      "MYA",
      "BRVO",
      "TSLN",
      "ERM",
      "LS",
      "MS",
      "CSR",
      "ODC",
      "CRVO",
      "TV",
      "AH",
      "ODP",
      "ODE",
      "ST",
      "AION",
      "PT",
      "RT",
      "RS",
      "CRS",
      "EDN",
      "RPEC",
      "MHL",
      "RP",
      "CWS",
      "CB",
      "ODPM",
      "PRH",
      "MNF",
      "HR",
      "CRAO",
      "TD",
      "CME",
      "PTCR",
      "CF",
      "VH",
      "MCA",
      "VS",
      "BRAO",
      "PLQ",
      "HPED",
      "CL"
    ],
    "input_shape": [
      1,
      3,
      224,
      224
    ],
    "output_shape": [
      1,
      45
    ],
    "quantization_dtype": "float16"
  },
  "preprocessing": {
    "mean": [
      0.485,
      0.456,
      0.406
    ],
    "std": [
      0.229,
      0.224,
      0.225
    ],
    "resize": [
      224,
      224
    ]
  },
  "export_info": {
    "export_order": "PyTorch format only for maximum compatibility",
    "formats_skipped": [
      "TFLite",
      "ONNX",
      "TorchScript"
    ],
    "skip_reason": "Focus on PyTorch format for core deployment",
    "knowledge_graph_injected": true
  },
  "deployment": {
    "formats": [
      "PyTorch (.pth)"
    ],
    "server_deployment": "PyTorch (.pth) - Full precision model",
    "api_endpoint": "/predict",
    "max_batch_size": 32,
    "quantization_note": "Uses modern float16 weight-only quantization (replaces deprecated quantize_dynamic)",
    "clinical_features": "Knowledge graph for enhanced clinical reasoning and referral prioritization"
  }
}